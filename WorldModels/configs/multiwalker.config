# TODO: make this json someday
exp_name=WorldModels
env_name=multiwalker_v9
max_frames=1002 # max number of steps that each multiwalker will take in env
min_frames=100
max_trials=12000 # 10 ## 12k is what was used for rollout in original paper
render_mode=False
full_episode=True
exp_mode=4 # same as ZH
a_width=4   
z_size=31
state_space=2 # 1: include hidden state, 2: include hidden state and c
vae_batch_size=100
vae_learning_rate=0.0001
vae_kl_tolerance=0.5
vae_num_epoch=10

rnn_num_steps=100 #40000
rnn_max_seq_len=1002 # train on sequences of 1000
rnn_input_seq_width=38 # z (31)+ agent ID (3) + a (4)
rnn_out_size=510 # 3 x num_mixture (5) x (z_size+agent ID)
rnn_size=256 # size of hidden/cell state
rnn_batch_size=102
rnn_grad_clip=1.0
rnn_num_mixture=5 # number of mixtures in MDN
rnn_learning_rate=0.001
rnn_decay_rate=0.99999
rnn_min_learning_rate=0.00001

controller_optimizer=cma
controller_num_episode=16
controller_num_test_episode=10  #100 ## Number of rollout simulations to use to evaluate the controller while it's being optimzed
controller_eval_steps=10        ## Number of optimzation cycles to run before evaluating
controller_num_worker=64        ## This is for threading
controller_num_worker_trial=1   
controller_antithetic=1 ## Unsure what this does
controller_cap_time=1   ## Sets a time limit for training
controller_retrain=0
controller_seed_start=0
controller_sigma_init=0.1
controller_sigma_decay=0.999
controller_batch_mode=mean